{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install xgboost\n",
    "!pip install catboost\n",
    "!pip install lightgbm\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import catboost as cat_\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import HalvingGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Drop MPG because of the same value in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train.drop(['MRG'], axis = 1, inplace=True)\n",
    "test.drop(['MRG'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Drop user_id from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train.drop(['user_id'], axis = 1, inplace=True)\n",
    "test.drop(['user_id'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Drop top packs for the first iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train.drop(['TOP_PACK'], axis = 1, inplace=True)\n",
    "test.drop(['TOP_PACK'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convert tenure into the int format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train['TENURE'] = train['TENURE'].map({'K > 24 month': 24, 'I 18-21 month': 18, 'H 15-18 month': 15, \n",
    "                                       'G 12-15 month':12, 'J 21-24 month': 21, 'F 9-12': 9,\n",
    "                                       'E 6-9 month':6, 'D 3-6 month':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test['TENURE'] = test['TENURE'].map({'K > 24 month': 24, 'I 18-21 month': 18, 'H 15-18 month': 15, \n",
    "                                       'G 12-15 month':12, 'J 21-24 month': 21, 'F 9-12': 9,\n",
    "                                       'E 6-9 month':6, 'D 3-6 month':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train['TENURE'].fillna(1, inplace=True) # fill nans with unkown\n",
    "test['TENURE'].fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "X / y samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y = train['CHURN']\n",
    "train.drop(['CHURN'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X = train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train-val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X, X_val, y, y_val = train_test_split(X,y,test_size = 0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Encoding of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X['REGION'].fillna('other', inplace=True) # fill nans with unkown\n",
    "X_val['REGION'].fillna('other', inplace=True) \n",
    "test['REGION'].fillna('other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder() \n",
    "X['REGION'] = encoder.fit_transform(X['REGION'])\n",
    "X_val['REGION'] = encoder.transform(X_val['REGION'])\n",
    "test['REGION'] = encoder.transform(test['REGION'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "num_cols = ['MONTANT', 'FREQUENCE_RECH', 'REVENUE', 'ARPU_SEGMENT', 'FREQUENCE',\n",
    "       'DATA_VOLUME', 'ON_NET', 'ORANGE', 'TIGO', 'ZONE1', 'ZONE2',\n",
    "       'REGULARITY', 'FREQ_TOP_PACK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "X_val[num_cols] = scaler.transform(X_val[num_cols])\n",
    "test[num_cols] = scaler.transform(test[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Imputing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "imp = imp.fit(X[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X[num_cols] = imp.transform(X[num_cols])\n",
    "X_val[num_cols] = imp.transform(X_val[num_cols])\n",
    "test[num_cols] = imp.transform(test[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def eval_metrics(y_test, y_pred):\n",
    "    print('Precision Score: ', round(precision_score(y_val, y_pred), 3))\n",
    "    print('Recall Score: ', round(recall_score(y_val, y_pred), 3))\n",
    "    print('F1 Score: ', round(f1_score(y_val, y_pred), 3))\n",
    "    print('Accuracy Score: ', round(accuracy_score(y_val, y_pred), 3))\n",
    "    print('ROC AUC: ', round(roc_auc_score(y_val, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Submission preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def prepare_submission(submission, test, model, name):\n",
    "    sub_pred = model.predict(test)\n",
    "    submission['CHURN'] = sub_pred\n",
    "    return submission.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'max_features': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "              'ccp_alpha': [0.1, .01, .001],\n",
    "              'min_samples_leaf': [3, 4, 5, 6, 7],\n",
    "              'max_depth' : [5, 6, 7],\n",
    "              'criterion' :['gini', 'entropy']\n",
    "             }\n",
    "\n",
    "tree_clas = DecisionTreeClassifier(random_state=124)\n",
    "grid_search = HalvingGridSearchCV(estimator=tree_clas, param_grid=param_grid, scoring='roc_auc', cv=3, verbose=False)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tree_clas = DecisionTreeClassifier(ccp_alpha=0.001, criterion='entropy', max_depth=7,\n",
    "                                   max_features=0.5, min_samples_leaf=7, random_state=124)\n",
    "tree_clas.fit(X, y)\n",
    "\n",
    "tree_ypred = tree_clas.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "eval_metrics(y_val, tree_ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "prepare_submission(submission, test, tree_clas, '1_tree_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [100, 200, 500],\n",
    "              'max_features': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "              'max_depth' : [4,5,6,7,8,10],\n",
    "              'criterion' :['gini', 'entropy']\n",
    "             }\n",
    "\n",
    "rand = RandomForestClassifier(random_state=124)\n",
    "grid_search_rfc = HalvingGridSearchCV(estimator=rand, param_grid=param_grid, scoring='roc_auc', cv=3, verbose=False)\n",
    "grid_search_rfc.fit(X, y)\n",
    "grid_search_rfc.best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "grid_search_rfc.best_params_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(criterion='entropy', max_depth=8,\n",
    "                                 max_features=0.5, n_estimators = 500, random_state=124)\n",
    "rf_clf.fit(X, y)\n",
    "\n",
    "rf_ypred = rf_clf.predict(X_val)\n",
    "eval_metrics(y_val, rf_ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "prepare_submission(submission, test, rf_clf, '2_randforest_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "              'min_samples_split': [0.05, 0.1, 0.2, 0.5],\n",
    "              'min_samples_leaf': [0.05, 0.1, 0.2, 0.5],\n",
    "              'max_depth':[3,5,7,8],\n",
    "              'max_features':['log2','sqrt'],\n",
    "              'criterion': ['friedman_mse',  'mae'],\n",
    "              'subsample':[0.5, 0.6, 0.8, 0.9, 1.0],\n",
    "              'n_estimators':[10, 100, 200]\n",
    "             }\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=124)\n",
    "grid_search_gb = HalvingGridSearchCV(estimator=gb, param_grid=param_grid, scoring='roc_auc', cv=3, verbose=True)\n",
    "grid_search_gb.fit(X, y)\n",
    "grid_search_gb.best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "grid_search_gb.best_params_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(... random_state=124)\n",
    "gb_clf.fit(X, y)\n",
    "\n",
    "gb_ypred = gb_clf.predict(X_val)\n",
    "eval_metrics(y_val, rf_ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "prepare_submission(submission, test, rf_clf, '2_randforest_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Knn KNeighborsClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 10, 15], \n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'metric': ['euclidean', 'minkowski', 'manhattan', 'chebyshev']\n",
    "              }\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search_knn = HalvingGridSearchCV(estimator=knn, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=False, n_jobs=-1)\n",
    "grid_search_knn.fit(X, y)\n",
    "grid_search_knn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "grid_search_knn.best_params_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(... random_state=124)\n",
    "knn_clf.fit(X, y)\n",
    "\n",
    "knn_ypred = knn_clf.predict(X_val)\n",
    "eval_metrics(y_val, rf_ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "prepare_submission(submission, test, knn_clf, '3_knn_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Naive bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "param_grid_nb = {'var_smoothing': np.logspace(0,-9, num=20)}\n",
    "\n",
    "nb = GaussianNB()\n",
    "grid_search_nb = HalvingGridSearchCV(estimator=nb, param_grid=param_grid_nb, scoring='roc_auc', cv=5, verbose=False, n_jobs=-1)\n",
    "grid_search_nb.fit(X, y)\n",
    "grid_search_nb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "grid_search_nb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "gnb_model = GaussianNB(var_smoothing = 0.00428)\n",
    "gnb_model.fit(X, y)\n",
    "\n",
    "gnb_pred = gnb_model.predict(X_val)\n",
    "eval_metrics(y_val, gnb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "prepare_submission(submission, test, gnb_model, '5_naivebayes_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'solver': ['newton-cg', 'sag', 'lbfgs'],\n",
    "              'penalty': ['l2', 'none'], \n",
    "              'C': np.logspace(-3,3,7)\n",
    "              }\n",
    "\n",
    "lr = LogisticRegression()\n",
    "grid_search_lr = HalvingGridSearchCV(estimator=lr, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=False, n_jobs=-1)\n",
    "grid_search_lr.fit(X, y)\n",
    "grid_search_lr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "grid_search_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "lr_model =  LogisticRegression(C=0.01, penalty='l2', solver='newton-cg')\n",
    "lr_model.fit(X, y)\n",
    "\n",
    "lr_pred = lr_model.predict(X_val)\n",
    "eval_metrics(y_val, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "prepare_submission(submission, test, lr_model, '4_logisticregression_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### SVM (SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Вероятно плохо сработает, так как большой датасет и классы несбалансированные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "clf_svc = svm.LinearSVC()\n",
    "feature_map_nystroem = Nystroem(gamma=.2, \n",
    "                                random_state=1, n_components=300)\n",
    "data_transformed = feature_map_nystroem.fit_transform(X)\n",
    "clf_svc.fit(data_transformed, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}